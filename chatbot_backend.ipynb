{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agriculture RAG Chatbot - Backend Logic\n",
    "\n",
    "This notebook contains the complete backend logic for the Livestock Advisor chatbot.\n",
    "\n",
    "**Components:**\n",
    "1. Configuration Settings\n",
    "2. Database Operations (SQL Server)\n",
    "3. RAG System (Firestore + Vector Search)\n",
    "4. LangGraph Agent (Query Classification & Response Generation)\n",
    "5. Chat Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if dependencies are not installed\n",
    "# !pip install python-dotenv pymssql pandas google-cloud-firestore langchain-google-vertexai langchain-google-genai langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Database Configuration\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\", \"\").strip(),\n",
    "    \"port\": int(os.getenv(\"DB_PORT\", \"1433\").strip()),\n",
    "    \"user\": os.getenv(\"DB_USER\", \"\").strip(),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\", \"\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\", \"\").strip(),\n",
    "}\n",
    "\n",
    "# Allowed tables for security\n",
    "ALLOWED_TABLES = [\n",
    "    \"Speciesavailable\",\n",
    "    \"Speciesbreedlookuptable\",\n",
    "    \"Speciescategory\",\n",
    "    \"Speciescolorlookuptable\",\n",
    "    \"Speciespatternlookuptable\",\n",
    "    \"Speciesregistrationtypelookuptable\",\n",
    "]\n",
    "\n",
    "# GCP Configuration\n",
    "GCP_PROJECT = os.getenv(\"GOOGLE_CLOUD_PROJECT\", \"\").strip()\n",
    "GCP_LOCATION = os.getenv(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\").strip()\n",
    "GCP_CREDENTIALS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\", \"\").strip()\n",
    "\n",
    "# Determine if using Vertex AI\n",
    "USE_VERTEX_AI = bool(GCP_PROJECT)\n",
    "\n",
    "# LLM Configuration\n",
    "if USE_VERTEX_AI:\n",
    "    LLM_MODEL = os.getenv(\"VERTEX_AI_MODEL\", \"gemini-2.0-flash-001\")\n",
    "else:\n",
    "    LLM_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-2.0-flash\")\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\").strip()\n",
    "\n",
    "# RAG Configuration\n",
    "EMBEDDING_MODEL = \"text-embedding-004\"\n",
    "EMBEDDING_DIMENSIONS = 768\n",
    "TOP_K_RESULTS = 10\n",
    "\n",
    "# Firestore Configuration\n",
    "FIRESTORE_DATABASE = os.getenv(\"FIRESTORE_DATABASE\", \"(default)\").strip()\n",
    "FIRESTORE_COLLECTION = \"livestock_knowledge\"\n",
    "\n",
    "# Print configuration\n",
    "if USE_VERTEX_AI:\n",
    "    print(f\"[Config] Using Vertex AI (Project: {GCP_PROJECT}, Location: {GCP_LOCATION})\")\n",
    "else:\n",
    "    print(\"[Config] Using Google AI API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "\n",
    "class Database:\n",
    "    \"\"\"Manages database connections and queries.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._connection = None\n",
    "        self._allowed_tables = [t.lower() for t in ALLOWED_TABLES]\n",
    "\n",
    "    @property\n",
    "    def connection(self):\n",
    "        \"\"\"Lazy connection to database.\"\"\"\n",
    "        if self._connection is None:\n",
    "            try:\n",
    "                self._connection = pymssql.connect(\n",
    "                    server=DB_CONFIG[\"host\"],\n",
    "                    port=DB_CONFIG[\"port\"],\n",
    "                    user=DB_CONFIG[\"user\"],\n",
    "                    password=DB_CONFIG[\"password\"],\n",
    "                    database=DB_CONFIG[\"database\"],\n",
    "                    as_dict=True\n",
    "                )\n",
    "                print(f\"[DB] Connected to {DB_CONFIG['database']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[DB] Connection failed: {e}\")\n",
    "                raise\n",
    "        return self._connection\n",
    "\n",
    "    def _validate_query(self, query: str) -> None:\n",
    "        \"\"\"Validate query only accesses allowed tables.\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        tables = re.findall(r'from\\s+\\[?(\\w+)\\]?', query_lower)\n",
    "        tables += re.findall(r'join\\s+\\[?(\\w+)\\]?', query_lower)\n",
    "\n",
    "        for table in tables:\n",
    "            if table not in self._allowed_tables:\n",
    "                raise PermissionError(f\"Access denied to table: {table}\")\n",
    "\n",
    "    def execute(self, query: str) -> pd.DataFrame:\n",
    "        \"\"\"Execute a SELECT query and return results as DataFrame.\"\"\"\n",
    "        self._validate_query(query)\n",
    "\n",
    "        cursor = self.connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        return pd.DataFrame(results) if results else pd.DataFrame()\n",
    "\n",
    "    def get_schema(self) -> str:\n",
    "        \"\"\"Get schema for all allowed tables.\"\"\"\n",
    "        schema_parts = []\n",
    "        cursor = self.connection.cursor()\n",
    "\n",
    "        for table in ALLOWED_TABLES:\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT COLUMN_NAME, DATA_TYPE\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                WHERE TABLE_NAME = '{table}'\n",
    "            \"\"\")\n",
    "            cols = cursor.fetchall()\n",
    "            if cols:\n",
    "                schema_parts.append(f\"-- {table}\")\n",
    "                for col in cols:\n",
    "                    schema_parts.append(f\"   {col['COLUMN_NAME']} ({col['DATA_TYPE']})\")\n",
    "\n",
    "        return \"\\n\".join(schema_parts)\n",
    "\n",
    "    def get_all_species(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all species with their details.\"\"\"\n",
    "        df = self.execute(\"\"\"\n",
    "            SELECT SpeciesID, Species, MaleTerm, FemaleTerm, BabyTerm,\n",
    "                   SingularTerm, PluralTerm, GestationPeriod\n",
    "            FROM Speciesavailable\n",
    "            WHERE SpeciesAvailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_breeds_for_species(self, species_id: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all breeds for a specific species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT b.BreedLookupID, b.Breed, b.Breeddescription,\n",
    "                   b.MeatBreed, b.MilkBreed, b.WoolBreed, b.EggBreed, b.Working,\n",
    "                   s.Species\n",
    "            FROM Speciesbreedlookuptable b\n",
    "            JOIN Speciesavailable s ON b.SpeciesID = s.SpeciesID\n",
    "            WHERE b.SpeciesID = {species_id} AND b.breedavailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_all_breeds(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all breeds with species info.\"\"\"\n",
    "        df = self.execute(\"\"\"\n",
    "            SELECT TOP 2000 b.BreedLookupID, b.Breed, b.Breeddescription,\n",
    "                   b.MeatBreed, b.MilkBreed, b.WoolBreed, b.EggBreed, b.Working,\n",
    "                   s.Species, s.SpeciesID\n",
    "            FROM Speciesbreedlookuptable b\n",
    "            JOIN Speciesavailable s ON b.SpeciesID = s.SpeciesID\n",
    "            WHERE b.breedavailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_colors_for_species(self, species_id: int) -> List[str]:\n",
    "        \"\"\"Get available colors for a species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT DISTINCT SpeciesColor\n",
    "            FROM Speciescolorlookuptable\n",
    "            WHERE SpeciesID = {species_id}\n",
    "        \"\"\")\n",
    "        return df['SpeciesColor'].tolist() if not df.empty else []\n",
    "\n",
    "    def get_patterns_for_species(self, species_id: int) -> List[str]:\n",
    "        \"\"\"Get available patterns for a species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT DISTINCT SpeciesColor as Pattern\n",
    "            FROM Speciespatternlookuptable\n",
    "            WHERE SpeciesID = {species_id}\n",
    "        \"\"\")\n",
    "        return df['Pattern'].tolist() if not df.empty else []\n",
    "\n",
    "    def get_categories_for_species(self, species_id: int) -> List[str]:\n",
    "        \"\"\"Get categories for a species.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT SpeciesCategory\n",
    "            FROM Speciescategory\n",
    "            WHERE SpeciesID = {species_id}\n",
    "            ORDER BY SpeciesCategoryOrder\n",
    "        \"\"\")\n",
    "        return df['SpeciesCategory'].tolist() if not df.empty else []\n",
    "\n",
    "    def search_breeds(self, search_term: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search breeds by name.\"\"\"\n",
    "        df = self.execute(f\"\"\"\n",
    "            SELECT TOP 20 b.Breed, b.Breeddescription, s.Species,\n",
    "                   b.MeatBreed, b.MilkBreed, b.WoolBreed, b.EggBreed\n",
    "            FROM Speciesbreedlookuptable b\n",
    "            JOIN Speciesavailable s ON b.SpeciesID = s.SpeciesID\n",
    "            WHERE b.Breed LIKE '%{search_term}%' AND b.breedavailable = 1\n",
    "        \"\"\")\n",
    "        return df.to_dict('records') if not df.empty else []\n",
    "\n",
    "    def get_database_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get a summary of database contents.\"\"\"\n",
    "        summary = {}\n",
    "\n",
    "        # Count species\n",
    "        df = self.execute(\"SELECT COUNT(*) as cnt FROM Speciesavailable WHERE SpeciesAvailable = 1\")\n",
    "        summary['total_species'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        # Count breeds\n",
    "        df = self.execute(\"SELECT COUNT(*) as cnt FROM Speciesbreedlookuptable WHERE breedavailable = 1\")\n",
    "        summary['total_breeds'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        # Count colors\n",
    "        df = self.execute(\"SELECT COUNT(DISTINCT SpeciesColor) as cnt FROM Speciescolorlookuptable\")\n",
    "        summary['total_colors'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        # Count patterns\n",
    "        df = self.execute(\"SELECT COUNT(DISTINCT SpeciesColor) as cnt FROM Speciespatternlookuptable\")\n",
    "        summary['total_patterns'] = df['cnt'].iloc[0] if not df.empty else 0\n",
    "\n",
    "        return summary\n",
    "\n",
    "\n",
    "# Create database instance\n",
    "db = Database()\n",
    "print(\"[DB] Database class initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG System (Firestore + Vector Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure\n",
    "\n",
    "# Initialize embedding model based on configuration\n",
    "if USE_VERTEX_AI:\n",
    "    from langchain_google_vertexai import VertexAIEmbeddings\n",
    "    embeddings = VertexAIEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL,\n",
    "        project=GCP_PROJECT,\n",
    "        location=GCP_LOCATION\n",
    "    )\n",
    "    print(f\"[RAG] Using Vertex AI Embeddings ({EMBEDDING_MODEL})\")\n",
    "else:\n",
    "    from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=f\"models/{EMBEDDING_MODEL}\",\n",
    "        google_api_key=GOOGLE_API_KEY\n",
    "    )\n",
    "    print(f\"[RAG] Using Google AI Embeddings ({EMBEDDING_MODEL})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"RAG system using Firestore Vector Search.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._db = None\n",
    "        self._initialized = False\n",
    "\n",
    "    @property\n",
    "    def firestore_db(self):\n",
    "        \"\"\"Lazy initialization of Firestore client.\"\"\"\n",
    "        if self._db is None:\n",
    "            self._db = firestore.Client(project=GCP_PROJECT, database=FIRESTORE_DATABASE)\n",
    "            print(f\"[RAG] Connected to Firestore (Project: {GCP_PROJECT})\")\n",
    "        return self._db\n",
    "\n",
    "    @property\n",
    "    def collection(self):\n",
    "        \"\"\"Get the Firestore collection.\"\"\"\n",
    "        return self.firestore_db.collection(FIRESTORE_COLLECTION)\n",
    "\n",
    "    def _get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embedding for text.\"\"\"\n",
    "        return embeddings.embed_query(text)\n",
    "\n",
    "    def _get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate embeddings for multiple texts.\"\"\"\n",
    "        return embeddings.embed_documents(texts)\n",
    "\n",
    "    def _format_breed_document(self, breed: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format breed data into a searchable document.\"\"\"\n",
    "        parts = [f\"Breed: {breed.get('Breed', 'Unknown')}\"]\n",
    "\n",
    "        if breed.get('Species'):\n",
    "            parts.append(f\"Species: {breed['Species']}\")\n",
    "\n",
    "        if breed.get('Breeddescription'):\n",
    "            parts.append(f\"Description: {breed['Breeddescription']}\")\n",
    "\n",
    "        purposes = []\n",
    "        if breed.get('MeatBreed'):\n",
    "            purposes.append(\"meat production\")\n",
    "        if breed.get('MilkBreed'):\n",
    "            purposes.append(\"milk/dairy production\")\n",
    "        if breed.get('WoolBreed'):\n",
    "            purposes.append(\"wool/fiber production\")\n",
    "        if breed.get('EggBreed'):\n",
    "            purposes.append(\"egg production\")\n",
    "        if breed.get('Working'):\n",
    "            purposes.append(\"working/draft animal\")\n",
    "\n",
    "        if purposes:\n",
    "            parts.append(f\"Purpose: {', '.join(purposes)}\")\n",
    "\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "    def _format_species_document(self, species: Dict[str, Any], colors: List[str],\n",
    "                                  patterns: List[str], categories: List[str]) -> str:\n",
    "        \"\"\"Format species data into a searchable document.\"\"\"\n",
    "        parts = [f\"Species: {species.get('Species', 'Unknown')}\"]\n",
    "\n",
    "        if species.get('SingularTerm'):\n",
    "            parts.append(f\"Singular: {species['SingularTerm']}\")\n",
    "        if species.get('PluralTerm'):\n",
    "            parts.append(f\"Plural: {species['PluralTerm']}\")\n",
    "        if species.get('MaleTerm'):\n",
    "            parts.append(f\"Male term: {species['MaleTerm']}\")\n",
    "        if species.get('FemaleTerm'):\n",
    "            parts.append(f\"Female term: {species['FemaleTerm']}\")\n",
    "        if species.get('BabyTerm'):\n",
    "            parts.append(f\"Baby term: {species['BabyTerm']}\")\n",
    "        if species.get('GestationPeriod'):\n",
    "            parts.append(f\"Gestation period: {species['GestationPeriod']} days\")\n",
    "\n",
    "        if colors:\n",
    "            parts.append(f\"Available colors: {', '.join(colors[:20])}\")\n",
    "        if patterns:\n",
    "            parts.append(f\"Available patterns: {', '.join(patterns[:20])}\")\n",
    "        if categories:\n",
    "            parts.append(f\"Categories: {', '.join(categories[:15])}\")\n",
    "\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "    def _check_if_indexed(self) -> bool:\n",
    "        \"\"\"Check if data is already indexed in Firestore.\"\"\"\n",
    "        docs = self.collection.limit(1).get()\n",
    "        return len(list(docs)) > 0\n",
    "\n",
    "    def _get_document_count(self) -> int:\n",
    "        \"\"\"Get the count of documents in the collection using aggregation.\"\"\"\n",
    "        try:\n",
    "            count_query = self.collection.count()\n",
    "            result = count_query.get()\n",
    "            return result[0][0].value\n",
    "        except Exception as e:\n",
    "            print(f\"[RAG] Warning: Could not get document count: {e}\")\n",
    "            return -1\n",
    "\n",
    "    def index_database(self, force_rebuild: bool = False) -> int:\n",
    "        \"\"\"Index all livestock data to Firestore with embeddings.\"\"\"\n",
    "        # Check if already indexed\n",
    "        if not force_rebuild and self._check_if_indexed():\n",
    "            count = self._get_document_count()\n",
    "            if count >= 0:\n",
    "                print(f\"[RAG] Using existing Firestore index ({count} documents)\")\n",
    "            else:\n",
    "                print(\"[RAG] Using existing Firestore index\")\n",
    "            self._initialized = True\n",
    "            return max(count, 0)\n",
    "\n",
    "        print(\"[RAG] Building Firestore vector index from database...\")\n",
    "\n",
    "        # Clear existing documents if rebuilding\n",
    "        if force_rebuild:\n",
    "            print(\"[RAG] Clearing existing documents...\")\n",
    "            deleted_count = 0\n",
    "            while True:\n",
    "                docs = list(self.collection.limit(100).stream())\n",
    "                if not docs:\n",
    "                    break\n",
    "                batch = self.firestore_db.batch()\n",
    "                for doc in docs:\n",
    "                    batch.delete(doc.reference)\n",
    "                batch.commit()\n",
    "                deleted_count += len(docs)\n",
    "                print(f\"[RAG] Deleted {deleted_count} documents...\")\n",
    "\n",
    "        documents = []\n",
    "\n",
    "        # Prepare breed documents\n",
    "        print(\"[RAG] Preparing breed documents...\")\n",
    "        breeds = db.get_all_breeds()\n",
    "        for breed in breeds:\n",
    "            content = self._format_breed_document(breed)\n",
    "            documents.append({\n",
    "                \"id\": f\"breed_{breed.get('BreedLookupID', '')}\",\n",
    "                \"content\": content,\n",
    "                \"type\": \"breed\",\n",
    "                \"breed_name\": breed.get('Breed', ''),\n",
    "                \"species\": breed.get('Species', ''),\n",
    "                \"species_id\": str(breed.get('SpeciesID', ''))\n",
    "            })\n",
    "\n",
    "        # Prepare species documents\n",
    "        print(\"[RAG] Preparing species documents...\")\n",
    "        species_list = db.get_all_species()\n",
    "        for species in species_list:\n",
    "            species_id = species.get('SpeciesID')\n",
    "            colors = db.get_colors_for_species(species_id)\n",
    "            patterns = db.get_patterns_for_species(species_id)\n",
    "            categories = db.get_categories_for_species(species_id)\n",
    "\n",
    "            content = self._format_species_document(species, colors, patterns, categories)\n",
    "            documents.append({\n",
    "                \"id\": f\"species_{species_id}\",\n",
    "                \"content\": content,\n",
    "                \"type\": \"species\",\n",
    "                \"species_name\": species.get('Species', ''),\n",
    "                \"species_id\": str(species_id)\n",
    "            })\n",
    "\n",
    "        if not documents:\n",
    "            print(\"[RAG] No documents to index\")\n",
    "            return 0\n",
    "\n",
    "        # Generate embeddings in batches and store in Firestore\n",
    "        print(f\"[RAG] Generating embeddings for {len(documents)} documents...\")\n",
    "\n",
    "        batch_size = 20\n",
    "        total_indexed = 0\n",
    "\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            batch_docs = documents[i:i+batch_size]\n",
    "            contents = [doc[\"content\"] for doc in batch_docs]\n",
    "\n",
    "            # Generate embeddings\n",
    "            batch_embeddings = self._get_embeddings_batch(contents)\n",
    "\n",
    "            # Store in Firestore with embeddings\n",
    "            batch = self.firestore_db.batch()\n",
    "            for doc, embedding in zip(batch_docs, batch_embeddings):\n",
    "                doc_ref = self.collection.document(doc[\"id\"])\n",
    "                batch.set(doc_ref, {\n",
    "                    \"content\": doc[\"content\"],\n",
    "                    \"type\": doc[\"type\"],\n",
    "                    \"metadata\": {k: v for k, v in doc.items() if k not in [\"id\", \"content\", \"type\"]},\n",
    "                    \"embedding\": Vector(embedding)\n",
    "                })\n",
    "\n",
    "            batch.commit()\n",
    "            total_indexed += len(batch_docs)\n",
    "            print(f\"[RAG] Indexed {total_indexed}/{len(documents)}\")\n",
    "\n",
    "        self._initialized = True\n",
    "        print(f\"[RAG] Index complete: {total_indexed} documents in Firestore\")\n",
    "        return total_indexed\n",
    "\n",
    "    def search(self, query: str, n_results: int = TOP_K_RESULTS,\n",
    "               filter_type: Optional[str] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for relevant documents using vector similarity.\"\"\"\n",
    "        if not self._initialized and not self._check_if_indexed():\n",
    "            self.index_database()\n",
    "            self._initialized = True\n",
    "\n",
    "        # Generate query embedding\n",
    "        query_embedding = self._get_embedding(query)\n",
    "\n",
    "        # Perform vector search\n",
    "        collection_ref = self.collection\n",
    "\n",
    "        # Apply type filter if specified\n",
    "        if filter_type:\n",
    "            collection_ref = collection_ref.where(\"type\", \"==\", filter_type)\n",
    "\n",
    "        # Vector nearest neighbor search\n",
    "        vector_query = collection_ref.find_nearest(\n",
    "            vector_field=\"embedding\",\n",
    "            query_vector=Vector(query_embedding),\n",
    "            distance_measure=DistanceMeasure.COSINE,\n",
    "            limit=n_results\n",
    "        )\n",
    "\n",
    "        results = vector_query.get()\n",
    "\n",
    "        # Format results\n",
    "        formatted = []\n",
    "        for doc in results:\n",
    "            data = doc.to_dict()\n",
    "            formatted.append({\n",
    "                \"content\": data.get(\"content\", \"\"),\n",
    "                \"metadata\": data.get(\"metadata\", {}),\n",
    "                \"type\": data.get(\"type\", \"unknown\"),\n",
    "                \"relevance_score\": 1.0\n",
    "            })\n",
    "\n",
    "        return formatted\n",
    "\n",
    "    def get_context_for_query(self, query: str) -> str:\n",
    "        \"\"\"Get formatted context string for LLM.\"\"\"\n",
    "        results = self.search(query)\n",
    "\n",
    "        if not results:\n",
    "            return \"No relevant information found in the database.\"\n",
    "\n",
    "        context_parts = [\"Relevant information from the livestock database:\\n\"]\n",
    "        for i, result in enumerate(results, 1):\n",
    "            context_parts.append(f\"{i}. {result['content']}\")\n",
    "            context_parts.append(f\"   (Type: {result['type']})\")\n",
    "            context_parts.append(\"\")\n",
    "\n",
    "        return \"\\n\".join(context_parts)\n",
    "\n",
    "\n",
    "# Create RAG instance\n",
    "rag = RAGSystem()\n",
    "print(\"[RAG] RAG System class initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangGraph Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Initialize LLM based on configuration\n",
    "if USE_VERTEX_AI:\n",
    "    from langchain_google_vertexai import ChatVertexAI\n",
    "    llm = ChatVertexAI(\n",
    "        model=LLM_MODEL,\n",
    "        project=GCP_PROJECT,\n",
    "        location=GCP_LOCATION,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    print(f\"[Agent] Using Vertex AI LLM ({LLM_MODEL})\")\n",
    "else:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=LLM_MODEL,\n",
    "        temperature=0.3,\n",
    "        google_api_key=GOOGLE_API_KEY\n",
    "    )\n",
    "    print(f\"[Agent] Using Google AI LLM ({LLM_MODEL})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict, total=False):\n",
    "    \"\"\"State for the chat agent.\"\"\"\n",
    "    messages: List[dict]\n",
    "    user_input: str\n",
    "    context: str\n",
    "    response: str\n",
    "    query_type: str  # \"livestock\" or \"general\"\n",
    "\n",
    "\n",
    "# Classification prompt\n",
    "CLASSIFICATION_PROMPT = \"\"\"Classify if the following user question is related to livestock, agriculture, animal breeds, or farming.\n",
    "\n",
    "Livestock-related topics include:\n",
    "- Animal breeds (cattle, sheep, goats, pigs, poultry, horses, etc.)\n",
    "- Species information, characteristics, terminology\n",
    "- Colors, patterns, categories of animals\n",
    "- Farming, breeding, animal husbandry\n",
    "- Agricultural practices related to animals\n",
    "\n",
    "Respond with ONLY one word: \"livestock\" if related, or \"general\" if not related.\n",
    "\n",
    "User question: {question}\n",
    "\n",
    "Classification:\"\"\"\n",
    "\n",
    "\n",
    "# System prompt for livestock queries\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert livestock advisor with access to a comprehensive database of animal breeds, species, colors, patterns, and categories.\n",
    "\n",
    "Your knowledge includes:\n",
    "- Detailed information about various livestock species (cattle, sheep, goats, pigs, poultry, horses, etc.)\n",
    "- Breed characteristics, purposes (meat, milk, wool, eggs, working), and descriptions\n",
    "- Available colors and patterns for each species\n",
    "- Terminology (male/female terms, baby terms, etc.)\n",
    "\n",
    "Guidelines:\n",
    "1. Use the provided context from the database to answer questions accurately\n",
    "2. Be helpful and informative about livestock breeds and species\n",
    "3. If asked about something not in the context, say so honestly\n",
    "4. Format responses clearly with bullet points or numbered lists when appropriate\n",
    "5. Be conversational but professional\n",
    "\n",
    "If the user asks about:\n",
    "- Breeds: Provide breed names, species, purpose, and descriptions\n",
    "- Species: Provide terminology, characteristics, and available breeds\n",
    "- Colors/Patterns: List available options for the species\n",
    "- General questions: Use your knowledge plus the database context\n",
    "\"\"\"\n",
    "\n",
    "# General assistant prompt (for non-livestock questions)\n",
    "GENERAL_PROMPT = \"\"\"You are a helpful, friendly assistant. Answer the user's question to the best of your ability.\n",
    "Be conversational but concise. If you don't know something, say so honestly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_query(state: ChatState) -> ChatState:\n",
    "    \"\"\"Classify if the query is livestock-related or general.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    if not user_input:\n",
    "        return {\"query_type\": \"general\"}\n",
    "\n",
    "    prompt = CLASSIFICATION_PROMPT.format(question=user_input)\n",
    "    response = llm.invoke(prompt)\n",
    "    classification = response.content.strip().lower()\n",
    "\n",
    "    # Default to livestock if classification is unclear\n",
    "    if \"livestock\" in classification:\n",
    "        query_type = \"livestock\"\n",
    "    else:\n",
    "        query_type = \"general\"\n",
    "\n",
    "    print(f\"[Agent] Query classified as: {query_type}\")\n",
    "    return {\"query_type\": query_type}\n",
    "\n",
    "\n",
    "def route_query(state: ChatState) -> str:\n",
    "    \"\"\"Route to RAG or direct response based on classification.\"\"\"\n",
    "    query_type = state.get(\"query_type\", \"general\")\n",
    "    if query_type == \"livestock\":\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        return \"generate_direct\"\n",
    "\n",
    "\n",
    "def retrieve_context(state: ChatState) -> ChatState:\n",
    "    \"\"\"Retrieve relevant context from RAG system.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    if not user_input:\n",
    "        return {\"context\": \"\"}\n",
    "\n",
    "    context = rag.get_context_for_query(user_input)\n",
    "    return {\"context\": context}\n",
    "\n",
    "\n",
    "def generate_response(state: ChatState) -> ChatState:\n",
    "    \"\"\"Generate response using LLM with RAG context.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    context = state.get(\"context\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt_parts = [SYSTEM_PROMPT]\n",
    "\n",
    "    if context:\n",
    "        prompt_parts.append(f\"\\n--- DATABASE CONTEXT ---\\n{context}\\n--- END CONTEXT ---\\n\")\n",
    "\n",
    "    # Add chat history (last 10 messages)\n",
    "    if messages:\n",
    "        prompt_parts.append(\"\\nRecent conversation:\")\n",
    "        for msg in messages[-10:]:\n",
    "            role = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "            prompt_parts.append(f\"{role}: {msg['content']}\")\n",
    "\n",
    "    prompt_parts.append(f\"\\nUser: {user_input}\\n\\nAssistant:\")\n",
    "\n",
    "    full_prompt = \"\\n\".join(prompt_parts)\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(full_prompt)\n",
    "    response_text = response.content\n",
    "\n",
    "    # Update messages\n",
    "    new_messages = list(messages)\n",
    "    new_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    new_messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "\n",
    "    return {\n",
    "        \"response\": response_text,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_direct(state: ChatState) -> ChatState:\n",
    "    \"\"\"Generate response using LLM directly without RAG context.\"\"\"\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt_parts = [GENERAL_PROMPT]\n",
    "\n",
    "    # Add chat history (last 10 messages)\n",
    "    if messages:\n",
    "        prompt_parts.append(\"\\nRecent conversation:\")\n",
    "        for msg in messages[-10:]:\n",
    "            role = \"User\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "            prompt_parts.append(f\"{role}: {msg['content']}\")\n",
    "\n",
    "    prompt_parts.append(f\"\\nUser: {user_input}\\n\\nAssistant:\")\n",
    "\n",
    "    full_prompt = \"\\n\".join(prompt_parts)\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(full_prompt)\n",
    "    response_text = response.content\n",
    "\n",
    "    # Update messages\n",
    "    new_messages = list(messages)\n",
    "    new_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    new_messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "\n",
    "    return {\n",
    "        \"response\": response_text,\n",
    "        \"messages\": new_messages\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    \"\"\"Build the LangGraph workflow with query classification and routing.\"\"\"\n",
    "    builder = StateGraph(ChatState)\n",
    "\n",
    "    # Add nodes\n",
    "    builder.add_node(\"classify\", classify_query)\n",
    "    builder.add_node(\"retrieve\", retrieve_context)\n",
    "    builder.add_node(\"generate\", generate_response)\n",
    "    builder.add_node(\"generate_direct\", generate_direct)\n",
    "\n",
    "    # Add edges with conditional routing\n",
    "    builder.add_edge(START, \"classify\")\n",
    "    builder.add_conditional_edges(\n",
    "        \"classify\",\n",
    "        route_query,\n",
    "        {\n",
    "            \"retrieve\": \"retrieve\",\n",
    "            \"generate_direct\": \"generate_direct\"\n",
    "        }\n",
    "    )\n",
    "    builder.add_edge(\"retrieve\", \"generate\")\n",
    "    builder.add_edge(\"generate\", END)\n",
    "    builder.add_edge(\"generate_direct\", END)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    return builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# Create the agent graph\n",
    "agent = build_graph()\n",
    "print(\"[Agent] LangGraph agent built successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, thread_id: str = \"default\") -> str:\n",
    "    \"\"\"\n",
    "    Send a message to the chatbot and get a response.\n",
    "\n",
    "    Args:\n",
    "        user_input: The user's message\n",
    "        thread_id: Session/thread identifier for conversation memory\n",
    "\n",
    "    Returns:\n",
    "        The agent's response\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    # Get current state to preserve message history\n",
    "    current_state = agent.get_state(config)\n",
    "    messages = current_state.values.get(\"messages\", []) if current_state.values else []\n",
    "\n",
    "    # Run the agent\n",
    "    result = agent.invoke(\n",
    "        {\"user_input\": user_input, \"messages\": messages},\n",
    "        config\n",
    "    )\n",
    "\n",
    "    return result.get(\"response\", \"I apologize, but I couldn't generate a response.\")\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    \"\"\"Initialize the RAG system by indexing the database.\"\"\"\n",
    "    print(\"[Agent] Initializing RAG system...\")\n",
    "    count = rag.index_database()\n",
    "    try:\n",
    "        summary = db.get_database_summary()\n",
    "        print(f\"[Agent] Ready! Database: {summary['total_species']} species, {summary['total_breeds']} breeds\")\n",
    "    except Exception:\n",
    "        print(\"[Agent] Ready! (SQL database unavailable)\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize & Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the system\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a livestock-related question\n",
    "response = chat(\"What cattle breeds are available for dairy production?\")\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a general question\n",
    "response = chat(\"What's the weather like to day?\")\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat loop (optional)\n",
    "def interactive_chat():\n",
    "    \"\"\"Run an interactive chat session.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Livestock Advisor Chatbot\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    thread_id = f\"interactive_{int(__import__('time').time())}\"\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        response = chat(user_input, thread_id)\n",
    "        print(f\"\\nAssistant: {response}\")\n",
    "\n",
    "# Uncomment to run interactive chat\n",
    "# interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
